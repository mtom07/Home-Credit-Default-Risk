# Home-Credit-Default-Risk
This Repository is to showcase my individual and group work completed when completing a Kaggle competition based around Home Credit Default Risk. 

# Business Problem and Project Goal
HomeCredit is an international credit lender that supports customers with little to no credit history. Their mission is to provide credit to those with little to no credit history. Because of this it puts HomeCredit at a higher risk of new loans defaulting. They need a way to predict which of their applicants should be approved for loans based around alternative credit factors. The goal of this project is to create a classification model, using variables form the provided data, that will provide a way for HomeCredit to predict the likelihood of an applicant defaulting on a loan. 

# Our Group Solution
For our solution we first each group member individually did an EDA. The results of this showed that with in the data we had a large imbalance in our Target (defaulting loans) vs non defaulting loans, 93% to 7%. Because of this we knew that our model would need to be able to outperform a majority class classifier. Also, from our EDA we were able to use feature engineering, imputing of data and removal of non-valuable factors to give us a training data set. 
With this training data set we then attempted 4 different classification modeling types, Logistic Regression, Gradient Boosted Trees, Random Forest, and Na√Øve Bayes. For each of the models we attempted different tuning methods to achieve the best results, based on an AUC score. Our selected model was our Logistic Regression. The Logistic Regression model gave us an AUC score .73 with a Kaggle score of .72. Though this model was not the highest scoring model we chose to use this as our solution as it gave us much more visibility into the factors of making our decisions. Overall, our solution was able to correctly identify 65% of all defaulting loans on our training set (4,882/7,447).

# Business Value
With our model in place, we were able to find many different value adds to the business problem. The first is our model was able to provide us with a list of important variables and how impactful these variables are in predicting default.  Our model is also able to provide a percentage estimate for each new applicant of default, giving the business the ability to lower or raise their risk amount. We also were able to draw up a net revenue simulation showing that our model when compared against a majority class classifier, was able to bring in 200% increase in net revenue. In this model we found that though HomeCredit would be approving less loans with our model, the number of loans approved that defaulted was also much lower resulting in increased overall revenue. 

# My Contribution
During the project I was able to contribute in 3 different areas, EDA, Modeling, Business Application. In the EDA section I provided suggestions around how to deal with missing data in the data set, ways to transform variables to be more explanatory, how to engineer new variables and provide a list of which variables would be strong predictors. In the modeling stage I lead the creation of the Random Forest model. I was able to use grid search to help provide a strong set of hyper-parameters. I also used different amounts of down and upsampeling. With this my model was the highest performing of the 4 models, achieving an AUC of .74 and a Kaggle score of .73. In the business application section, I drew up the net revenue simulation to help show how application of the model could potentially benefit the overall revenue of the business. 

# Difficulties
Throughout this process we found many difficulties. The first was the complexity of the data. There were many variables that were incomplete, imbalanced, or contained low variance. Figuring out how to use these variables was a very complex process. With our modeling we ran into some issues with computational time, specifically with our boosted trees and random forest models. As we were doing more complex and larger models, we found that there was a point where the amount spent computing the models was not providing an equal amount of return. We also needed to figure out many ways to address the target imbalance. Lastly the application of our model created some difficulty as far as if it achieved our overall goal. We found that our model was able to predict defaulting loans more accurately, but this was also at the cost of taking on less loans overall. As HomeCredits goal is to provide loans to those with no credit we would need to discuss if this new model is in line with that goal.

# Learnings
There were many new things learned while completing this project. During the EDA stage I was able to learn new methods of data cleaning, specifically how to deal with missing data. I was also able to learn new methods of how to quickly identify variables that have little to no variance to exclude them from modeling. In the modeling stage I learned much around how to use Tidymodels in R to create a workflow that can be changed and edited to attempt many different models quickly and easily. I also learned new methods of hyperparameter tunings via grid search and methods of addressing target imbalance while modeling. Apart from the technical work I was able to understand much more around the complexity of the loan business, specifically around how these types of businesses always must ride a fine line between risk and potential reward. 
![image](https://github.com/mtom07/Home-Credit-Default-Risk/assets/123605916/2205f506-cb2f-40c7-9a83-ff32ec707cba)
